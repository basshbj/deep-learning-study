{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 - FFNN Simple Test: XOR\n",
    "Simple Neural Network that is able to calculate XOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "## Neural Network definition\n",
    "input_size = 2 # Number of input features\n",
    "hidden_layer_nodes = 4 # Number of nodes in the hidden layer\n",
    "output_size = 1 # Number of output features\n",
    "\n",
    "## Training Parameters\n",
    "learning_rate = 0.01 # Value used to update weights\n",
    "num_epochs = 1000 # Number of iterations for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "X = np.array(\n",
    "  [\n",
    "    [0,0],\n",
    "    [0,1],\n",
    "    [1,0],\n",
    "    [1,1]\n",
    "  ]\n",
    ")\n",
    "\n",
    "Y = np.array(\n",
    "  [\n",
    "    [0],\n",
    "    [1],\n",
    "    [1],\n",
    "    [0]\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate weights\n",
    "The `np.random.rand` method generates a matrix with random values. \n",
    "The matrix dimensions (shape) is defined by the parameters `input_shape` and `hidden_layer_nodes`\n",
    "```\n",
    "X = input size = 2 (number of rows)\n",
    "Y = hidden_layer_nodes = 4 (number of columns)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden Layer Weights\n",
    "W1 = np.random.rand(input_size, hidden_layer_nodes)\n",
    "\n",
    "# Output Layer Weights\n",
    "W2 = np.random.rand(hidden_layer_nodes, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19967378, 0.51423444, 0.59241457, 0.04645041],\n",
       "       [0.60754485, 0.17052412, 0.06505159, 0.94888554]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96563203],\n",
       "       [0.80839735],\n",
       "       [0.30461377],\n",
       "       [0.09767211]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why is a matrix of zeros? Can be any random number?\n",
    "B1 = np.zeros((1, hidden_layer_nodes))\n",
    "B2 = np.zeros((1, output_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Activation Funtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feedforward function\n",
    "\n",
    "def relu(x):\n",
    "  return np.maximum(0, x)\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + np.exp(-x))\n",
    "\n",
    "## Backpropagation function\n",
    "def relu_derivative(x):\n",
    "  return np.where(x > 0, 1, 0).astype(float)\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "  return sigmoid(x) * (1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Loop\n",
    "- About Mean Squared Error https://www.geeksforgeeks.org/mean-squared-error/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logger\n",
    "log_data = []\n",
    "\n",
    "def save_log_data(epoch: int, loss: float, W1: np.ndarray, W2: np.ndarray, B1: np.ndarray, B2: np.ndarray):\n",
    "  item = {\n",
    "    \"epoch\": epoch,\n",
    "    \"loss\": loss,\n",
    "    \"W1\": W1.tolist(),\n",
    "    \"W2\": W2.tolist(),\n",
    "    \"B1\": B1.tolist(),\n",
    "    \"B2\": B2.tolist()\n",
    "  }\n",
    "\n",
    "  log_data.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Auxiliar methods\n",
    "\n",
    "# def hidden_layer(X: np.ndarray, W1: np.ndarray, B1: np.ndarray) -> np.ndarray:\n",
    "#   \"\"\"\n",
    "#   X  -> is the input data. It contains all the records and features. Expected matrix dimesion is (4, 2)\n",
    "#   W1 -> is the weight data. It is a matrix that contains all the weights for all the nodes in the hidden layer. Expected matrix dimenssion is (2,4)\n",
    "#   B1 -> is the bias data. Expected matrix dimension is (1, 4)\n",
    "\n",
    "#   Calculation process\n",
    "#   1 - Linear transformation\n",
    "#       z = (X * W1) + B1\n",
    "\n",
    "#   2 - Activation function\n",
    "#       a = relu(z)\n",
    "#   \"\"\"\n",
    "\n",
    "#   # 1 - Calculate the dot product of the input data and the weights\n",
    "#   #     Input data dimesion is (4.2)\n",
    "#   #     Weights dimesion is (2,4)\n",
    "#   #     Resulting dimension is (4,4)\n",
    "#   dot_product_result = np.dot(X, W1)\n",
    "\n",
    "#   # 2 - Add the bias to the dot product result\n",
    "#   #     Bias dimension is (1,4)\n",
    "#   #     Resulting dimension is (4,4)\n",
    "#   dot_product_result_bias = dot_product_result + B1\n",
    "\n",
    "#   # 3 - Apply the activation function ReLU\n",
    "#   #     Resulting dimension is (4,4)\n",
    "#   activated_result = relu(dot_product_result_bias)\n",
    "\n",
    "#   return activated_result\n",
    "\n",
    "\n",
    "# def output_layer(A1: np.ndarray, W2: np.ndarray, B2: np.ndarray) -> np.ndarray:\n",
    "#   \"\"\"\n",
    "#   A1 -> result of the hidden layer. Expected matrix dimesion is (4, 4)\n",
    "#   W2 -> is the weight data. It is a matrix that contains all the weights for all the nodes in the output layer. Expected matrix dimenssion is (4, 1)\n",
    "#   B1 -> is the bias data. Expected matrix dimension is (1, 1)\n",
    "\n",
    "#   Calculation process\n",
    "#   1 - Linear transformation\n",
    "#       z = (X * W1) + B1\n",
    "\n",
    "#   2 - Activation function\n",
    "#       a = relu(z)\n",
    "#   \"\"\"\n",
    "\n",
    "#   # 1 - Calculate the dot product of the input data and the weights\n",
    "#   #     Input data dimesion is (4.2)\n",
    "#   #     Weights dimesion is (2,4)\n",
    "#   #     Resulting dimension is (4,4)\n",
    "#   dot_product_result = np.dot(A1, W2)\n",
    "\n",
    "#   # 2 - Add the bias to the dot product result\n",
    "#   #     Bias dimension is (1,4)\n",
    "#   #     Resulting dimension is (4,4)\n",
    "#   dot_product_result_bias = dot_product_result + B2\n",
    "\n",
    "#   # 3 - Apply the activation function ReLU\n",
    "#   #     Resulting dimension is (4,4)\n",
    "#   activated_result = sigmoid(dot_product_result_bias)\n",
    "\n",
    "#   return activated_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "  # Forward Propagation\n",
    "  Z1 = np.dot(X, W1) + B1   # Input to hidden layer\n",
    "  A1 = relu(Z1)             # Activation of hidden layer\n",
    "\n",
    "  Z2 = np.dot(A1, W2) + B2  # Input to output layer\n",
    "  A2 = sigmoid(Z2)          # Activation of output layer\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "  # Calculate loss\n",
    "  loss = np.mean((Y - A2) ** 2) # Mean Squared Error\n",
    "\n",
    "  # Backpropagation\n",
    "  dA2 = A2 - Y\n",
    "  dZ2 = dA2 * sigmoid_derivative(Z2)\n",
    "  dW2 = np.dot(A1.T, dZ2)\n",
    "  dB2 = np.sum(dZ2, axis=0, keepdims=True)\n",
    "\n",
    "  dA1 = np.dot(dZ2, W2.T)\n",
    "  dZ1 = dA1 * relu_derivative(Z1)\n",
    "  dW1 = np.dot(X.T, dZ1)\n",
    "  dB1 = np.sum(dZ1, axis=0, keepdims=True)\n",
    "\n",
    "  # Update weights and biases\n",
    "  W2 -= learning_rate * dW2\n",
    "  B2 -= learning_rate * dB2\n",
    "  W1 -= learning_rate * dW1\n",
    "  B1 -= learning_rate * dB1\n",
    "\n",
    "  # Print loss every 10 epochs\n",
    "  if epoch % 10 == 0:\n",
    "    #save_log_data(epoch, loss, W1, W2, B1, B2)\n",
    "    print(f\"Epoch: {epoch}, Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.22227211772624472\n",
      "\n",
      "Epoch: 10, Loss: 0.22175984860688952\n",
      "\n",
      "Epoch: 20, Loss: 0.22123937896581808\n",
      "\n",
      "Epoch: 30, Loss: 0.22077822623300458\n",
      "\n",
      "Epoch: 40, Loss: 0.22025100256428104\n",
      "\n",
      "Epoch: 50, Loss: 0.21975958870336593\n",
      "\n",
      "Epoch: 60, Loss: 0.21923390537562565\n",
      "\n",
      "Epoch: 70, Loss: 0.2186768655535238\n",
      "\n",
      "Epoch: 80, Loss: 0.21820915742654934\n",
      "\n",
      "Epoch: 90, Loss: 0.2176697110892714\n",
      "\n",
      "Epoch: 100, Loss: 0.21719396370890848\n",
      "\n",
      "Epoch: 110, Loss: 0.21666020362606087\n",
      "\n",
      "Epoch: 120, Loss: 0.2160480277907648\n",
      "\n",
      "Epoch: 130, Loss: 0.21557946514572365\n",
      "\n",
      "Epoch: 140, Loss: 0.21496437369729632\n",
      "\n",
      "Epoch: 150, Loss: 0.21449945815383842\n",
      "\n",
      "Epoch: 160, Loss: 0.2138841254645089\n",
      "\n",
      "Epoch: 170, Loss: 0.2134195761654128\n",
      "\n",
      "Epoch: 180, Loss: 0.21276996173909152\n",
      "\n",
      "Epoch: 190, Loss: 0.21227589780635162\n",
      "\n",
      "Epoch: 200, Loss: 0.2117241164889248\n",
      "\n",
      "Epoch: 210, Loss: 0.21107772385548565\n",
      "\n",
      "Epoch: 220, Loss: 0.2105751100096449\n",
      "\n",
      "Epoch: 230, Loss: 0.20992736074071972\n",
      "\n",
      "Epoch: 240, Loss: 0.20942929998096516\n",
      "\n",
      "Epoch: 250, Loss: 0.20882194993918782\n",
      "\n",
      "Epoch: 260, Loss: 0.2082149834581727\n",
      "\n",
      "Epoch: 270, Loss: 0.20766666468147416\n",
      "\n",
      "Epoch: 280, Loss: 0.20696651532868576\n",
      "\n",
      "Epoch: 290, Loss: 0.20574575386964597\n",
      "\n",
      "Epoch: 300, Loss: 0.20462046362646374\n",
      "\n",
      "Epoch: 310, Loss: 0.2035459954674359\n",
      "\n",
      "Epoch: 320, Loss: 0.20256593885991905\n",
      "\n",
      "Epoch: 330, Loss: 0.20167721258870316\n",
      "\n",
      "Epoch: 340, Loss: 0.20088554938855774\n",
      "\n",
      "Epoch: 350, Loss: 0.19994734727797686\n",
      "\n",
      "Epoch: 360, Loss: 0.19900384329265305\n",
      "\n",
      "Epoch: 370, Loss: 0.19820866615608962\n",
      "\n",
      "Epoch: 380, Loss: 0.1972942089806645\n",
      "\n",
      "Epoch: 390, Loss: 0.19634109434394545\n",
      "\n",
      "Epoch: 400, Loss: 0.19548106976521354\n",
      "\n",
      "Epoch: 410, Loss: 0.19456227322737002\n",
      "\n",
      "Epoch: 420, Loss: 0.19374111040401992\n",
      "\n",
      "Epoch: 430, Loss: 0.1928687952731296\n",
      "\n",
      "Epoch: 440, Loss: 0.1918872051811012\n",
      "\n",
      "Epoch: 450, Loss: 0.1910296787390706\n",
      "\n",
      "Epoch: 460, Loss: 0.19008235260871897\n",
      "\n",
      "Epoch: 470, Loss: 0.18922118476912245\n",
      "\n",
      "Epoch: 480, Loss: 0.18839491406104147\n",
      "\n",
      "Epoch: 490, Loss: 0.1874995365290718\n",
      "\n",
      "Epoch: 500, Loss: 0.18663186601540135\n",
      "\n",
      "Epoch: 510, Loss: 0.1856664121485429\n",
      "\n",
      "Epoch: 520, Loss: 0.18476432197339449\n",
      "\n",
      "Epoch: 530, Loss: 0.18386773192668954\n",
      "\n",
      "Epoch: 540, Loss: 0.18297309113879737\n",
      "\n",
      "Epoch: 550, Loss: 0.18208755424319703\n",
      "\n",
      "Epoch: 560, Loss: 0.1812037656600501\n",
      "\n",
      "Epoch: 570, Loss: 0.18032075301583506\n",
      "\n",
      "Epoch: 580, Loss: 0.1793661595970192\n",
      "\n",
      "Epoch: 590, Loss: 0.17849134193563987\n",
      "\n",
      "Epoch: 600, Loss: 0.17761120668663\n",
      "\n",
      "Epoch: 610, Loss: 0.17664341106568945\n",
      "\n",
      "Epoch: 620, Loss: 0.17576931295320022\n",
      "\n",
      "Epoch: 630, Loss: 0.17489894269993358\n",
      "\n",
      "Epoch: 640, Loss: 0.17395372149028887\n",
      "\n",
      "Epoch: 650, Loss: 0.17309030284042623\n",
      "\n",
      "Epoch: 660, Loss: 0.1721609133546768\n",
      "\n",
      "Epoch: 670, Loss: 0.17117203243671003\n",
      "\n",
      "Epoch: 680, Loss: 0.17027545821855075\n",
      "\n",
      "Epoch: 690, Loss: 0.16937473841380962\n",
      "\n",
      "Epoch: 700, Loss: 0.16845009699270141\n",
      "\n",
      "Epoch: 710, Loss: 0.1676073449380929\n",
      "\n",
      "Epoch: 720, Loss: 0.1666912782580032\n",
      "\n",
      "Epoch: 730, Loss: 0.165743076615055\n",
      "\n",
      "Epoch: 740, Loss: 0.16487084475410893\n",
      "\n",
      "Epoch: 750, Loss: 0.1640288711470842\n",
      "\n",
      "Epoch: 760, Loss: 0.16322291558471982\n",
      "\n",
      "Epoch: 770, Loss: 0.16237306787644984\n",
      "\n",
      "Epoch: 780, Loss: 0.16146994878535603\n",
      "\n",
      "Epoch: 790, Loss: 0.16067806310874805\n",
      "\n",
      "Epoch: 800, Loss: 0.15985912210546918\n",
      "\n",
      "Epoch: 810, Loss: 0.15890770404553656\n",
      "\n",
      "Epoch: 820, Loss: 0.15810183805282194\n",
      "\n",
      "Epoch: 830, Loss: 0.15731195464942455\n",
      "\n",
      "Epoch: 840, Loss: 0.1563619704029098\n",
      "\n",
      "Epoch: 850, Loss: 0.15553041835495043\n",
      "\n",
      "Epoch: 860, Loss: 0.15466245393824807\n",
      "\n",
      "Epoch: 870, Loss: 0.15384962948609726\n",
      "\n",
      "Epoch: 880, Loss: 0.15292620786506558\n",
      "\n",
      "Epoch: 890, Loss: 0.15212025215314864\n",
      "\n",
      "Epoch: 900, Loss: 0.15123112582836135\n",
      "\n",
      "Epoch: 910, Loss: 0.15046870614996832\n",
      "\n",
      "Epoch: 920, Loss: 0.14946737855517353\n",
      "\n",
      "Epoch: 930, Loss: 0.14869518172020635\n",
      "\n",
      "Epoch: 940, Loss: 0.14776434295199653\n",
      "\n",
      "Epoch: 950, Loss: 0.14686987794495032\n",
      "\n",
      "Epoch: 960, Loss: 0.1460716249545165\n",
      "\n",
      "Epoch: 970, Loss: 0.14514081718590974\n",
      "\n",
      "Epoch: 980, Loss: 0.1443283231108915\n",
      "\n",
      "Epoch: 990, Loss: 0.14347241718403034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logger\n",
    "for item in log_data:\n",
    "  print(f\"Epoch: {item['epoch']}, Loss: {item['loss']}\")\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Loss: 0.2223\n",
      "Final Predictions\n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Final Loss: {loss:.4f}\")\n",
    "print(\"Final Predictions\")\n",
    "print(np.round(A2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
